{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# NLTK\n",
    "___\n"
   ],
   "id": "700c6019c3802579"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### üì¶ One-Time Setup (NLTK Resources)",
   "id": "17b64a5a35525229"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Load Dependencies",
   "id": "3957678e92123d8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T12:43:09.854947Z",
     "start_time": "2025-10-26T12:43:06.007445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import docx\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import html\n",
    "import ipywidgets as widgets, IPython, platform, ipywidgets, jupyterlab\n",
    "from importlib import reload\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ],
   "id": "9a5c2c52dd74d494",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T12:43:28.868078Z",
     "start_time": "2025-10-26T12:43:28.810594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import processing as pc\n",
    "reload( pc )\n",
    "from processing import Text"
   ],
   "id": "cbed53edd93bfdca",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:02:32.268493Z",
     "start_time": "2025-10-26T13:02:32.262023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fp = r'C:\\Users\\terry\\Desktop\\Test\\Text\\House Report 103-533.txt'\n",
    "src = r'C:/Users/terry/Desktop/Test/Text/'\n",
    "dst = r'C:/Users/terry/Desktop/Test/Corpora/'\n",
    "tx = Text( )"
   ],
   "id": "4c4a3094edae0ea",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T12:31:38.037564Z",
     "start_time": "2025-10-26T12:31:37.337455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = tx.load_text( fp )\n",
    "collapsed = tx.collapse_whitespace( text )\n",
    "compressed = tx.compress_whitespace( collapsed )\n",
    "normalized = tx.normalize_text( compressed )\n",
    "encoded = tx.remove_encodings( normalized )\n",
    "special = tx.remove_special( encoded )\n",
    "cleaned = tx.remove_fragments( special )\n",
    "recompress = tx.compress_whitespace( cleaned )\n",
    "sentences = tx.split_sentences( recompress )"
   ],
   "id": "96a2c3175c549513",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:03:23.376381Z",
     "start_time": "2025-10-26T13:02:39.843775Z"
    }
   },
   "cell_type": "code",
   "source": "tx.chunk_datasets( src, dst )",
   "id": "7f527d0a2ff69006",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üßÆ 1. Bag of Words (BoW) using CountVectorizer",
   "id": "93554b0db878266a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corpus = [ 'Bro loves clean code.', 'Code is life.' ]\n",
    "vectorizer = CountVectorizer( )\n",
    "X = vectorizer.fit_transform( corpus )\n",
    "\n",
    "print( vectorizer.get_feature_names_out( ) )\n",
    "print( X.toarray( ) )\n"
   ],
   "id": "df2a01ee327d57d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üìä 2. TF-IDF using TfidfVectorizer",
   "id": "606ca62c6f083d04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corpus = [ 'Bro writes awesome code.', 'Code must be clean and clear.' ]\n",
    "vectorizer = TfidfVectorizer( )\n",
    "X = vectorizer.fit_transform( corpus )\n",
    "\n",
    "print( vectorizer.get_feature_names_out( ) )\n",
    "print( X.toarray( ) )\n"
   ],
   "id": "58a4cf4ec025e261",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üß† 3. Word2Vec using gensim",
   "id": "cd392a973450c93a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sentences = [ [ 'bro', 'loves', 'python' ], [ 'clean', 'code', 'rocks' ] ]\n",
    "model = Word2Vec( sentences, vector_size=100, window=5, min_count=1, workers=4 )\n",
    "\n",
    "# VectorStore for the word 'bro'\n",
    "vector = model.wv[ 'bro' ]\n",
    "print( vector )\n"
   ],
   "id": "a20f65018fd9c119",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### üåç 4. GloVe using gensim (with pre-trained vectors)",
   "id": "8d6e939cb80ef619"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load GloVe vec (convert .txt to .word2vec format beforehand if needed)\n",
    "glove_file = r'C:\\Users\\terry\\source\\llm\\glove\\glove.6B.100d.txt'\n",
    "model = KeyedVectors.load_word2vec_format( glove_file, unicode_errors='ignore' )\n",
    "\n",
    "# VectorStore for the word 'code'\n",
    "vector = model[ 'code' ]\n",
    "print( vector )"
   ],
   "id": "fbd9b2a15ab86567"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ü§ñ 5. BERT / Transformer-based Embeddings using transformers + torch\n",
   "id": "8117a17e891dc4c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained( 'bert-base-uncased' )\n",
    "model = BertModel.from_pretrained( 'bert-base-uncased' )\n",
    "\n",
    "sentence = \"Bro's code always works.\"\n",
    "inputs = tokenizer( sentence, return_tensors='pt' )\n",
    "outputs = model( **inputs )\n",
    "\n",
    "# Get the vector for [CLS] token (sentence embedding)\n",
    "sentence_embedding = outputs.last_hidden_state[ :, 0, : ]\n",
    "print( sentence_embedding.shape )\n"
   ],
   "id": "8a9d362295bf0536",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
